{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwQRoPDxu9z7"
   },
   "source": [
    "* LangChain: https://python.langchain.com/en/latest/\n",
    "* OpenAI API: https://platform.openai.com/docs/\n",
    "* FAISS: https://github.com/facebookresearch/faiss\n",
    "* Pandas: https://pandas.pydata.org/docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BH2PaXdZvrFe",
    "outputId": "c2b01d5a-a457-4f95-8496-088dcbb01bf0"
   },
   "outputs": [],
   "source": [
    "# !pip install -Uq openai langchain langchain-openai faiss-cpu\n",
    "# !pip install -Uq langchain-community  langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zj6awYm_v1g-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "# from langchain.agents import create_pandas_dataframe_agent\n",
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "\n",
    "from google.colab import userdata\n",
    "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3nzCdxy9xBFj"
   },
   "outputs": [],
   "source": [
    "# 데이터베이스 연결 및 데이터 로드\n",
    "conn = sqlite3.connect('yes24_books_it.db')\n",
    "df = pd.read_sql_query(\"SELECT * FROM books\", conn)\n",
    "conn.close()\n",
    "\n",
    "# 제목과 설명을 결합한 필드 생성\n",
    "df[\"title_desc\"] = \"제목: \" + df[\"title\"] + \", 내용: \" + df[\"description\"]\n",
    "\n",
    "# 모든 관련 정보를 포함한 책 메타데이터 생성\n",
    "book_metadata = df.apply(lambda x: f\"제목: {x['title']} 저자: {x['author']} 출판사: {x['publisher']} \"\n",
    "                                   f\"출판일: {x['pub_date']} 가격: {x['price']} 할인: {x['discount']} \"\n",
    "                                   f\"평점: {x['rating']} 리뷰 수: {x['review_count']} 내용: {x['description']}\\n\\n\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pbwq73obu8jn",
    "outputId": "214f446a-b8e6-4493-b72e-90167c0f3536"
   },
   "outputs": [],
   "source": [
    "# OpenAI 임베딩 초기화\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# FAISS 벡터 저장소 생성\n",
    "vector_store = FAISS.from_texts(book_metadata.tolist(), embeddings)\n",
    "\n",
    "# 검색 및 질문-답변 체인 설정\n",
    "llm = ChatOpenAI(temperature=0.2)  # 더 일관된 응답을 위해 낮은 temperature 설정\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key=\"answer\")\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# AI 어시스턴트를 위한 프롬프트 템플릿\n",
    "prompt_template = \"\"\"당신은 IT 서적 전문가입니다. 주어진 정보를 바탕으로 사용자의 질문에 정확하고 상세하게 답변해주세요.\n",
    "답변 시 책 제목, 저자, 출판사 등의 정보를 포함해주세요.\n",
    "확실하지 않은 정보에 대해서는 \"확실하지 않습니다\"라고 말해주세요.\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변: \"\"\"\n",
    "\n",
    "# 질문하고 답변을 얻는 함수\n",
    "def ask_question(query):\n",
    "    result = qa_chain({\"question\": prompt_template.format(question=query)})\n",
    "    answer = result['answer']\n",
    "    sources = result['source_documents']\n",
    "\n",
    "    print(\"답변:\", answer)\n",
    "    print(\"\\n참고한 책:\")\n",
    "    for i, doc in enumerate(sources, 1):\n",
    "        print(f\"{i}. {doc.page_content.split('내용:')[0]}\")\n",
    "\n",
    "# 사용 예시\n",
    "query = \"챗GPT를 활용한 책의 제목은 무엇인가요?\"\n",
    "ask_question(query)\n",
    "\n",
    "# 더 복잡한 분석을 위한 Pandas DataFrame 에이전트 생성\n",
    "agent = create_pandas_dataframe_agent(OpenAI(temperature=0), df, verbose=True)\n",
    "\n",
    "# 데이터 분석을 위한 에이전트 사용 예시\n",
    "response = agent.run(\"평점과 리뷰 수를 분석하여 가장 인기 있는 책들의 특징을 설명해주세요. \"\n",
    "                     \"또한, 평점과 리뷰 수 사이의 상관관계가 있다면 그에 대해서도 설명해주세요.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3LYFPalvbus"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
