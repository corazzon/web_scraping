{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab17e4d0-eade-4338-88e3-6e0334693c39",
   "metadata": {},
   "source": [
    "1. **라이브러리 임포트**:\n",
    "   - `os`: 파일 입출력을 위해 사용.\n",
    "   - `sqlite3`: SQLite 데이터베이스를 관리하기 위해 사용.\n",
    "   - `openai`: OpenAI API를 사용하여 텍스트 번역을 처리.\n",
    "   - `pandas`: 데이터를 DataFrame으로 불러와 처리 및 분석하기 위해 사용.\n",
    "\n",
    "2. **OpenAI API 설정**:\n",
    "   - API 키는 환경 변수에서 불러와 설정.\n",
    "   - OpenAI API 클라이언트를 통해 텍스트 번역 작업을 처리.\n",
    "\n",
    "3. **텍스트 파일 읽기 및 분리**:\n",
    "   - 텍스트 파일을 개행 문자 기준으로 분리한 후, 텍스트를 일정 길이로 청크(1000자 단위)로 분할.\n",
    "\n",
    "4. **데이터베이스 생성 및 테이블 설정**:\n",
    "   - SQLite 데이터베이스를 생성하고, 텍스트 청크, 텍스트 길이, 번역 결과 등을 저장할 테이블(`chunks`)을 생성.\n",
    "\n",
    "5. **데이터베이스에 데이터 삽입**:\n",
    "   - 분할된 텍스트 청크를 데이터베이스에 삽입. 이때 번역 전 텍스트(`original_text`), 텍스트 길이(`length`), 번역 후 텍스트(`translation`), 번역된 텍스트의 길이(`translation_length`)를 저장.\n",
    "\n",
    "6. **OpenAI API를 활용한 텍스트 번역**:\n",
    "   - 번역 함수(`translate_text`)는 OpenAI의 GPT-4o-mini 모델을 사용하여 텍스트를 영어에서 한국어로 번역.\n",
    "   - 번역되지 않은 텍스트 청크를 데이터베이스에서 가져와, 번역 후 그 결과를 업데이트.\n",
    "\n",
    "7. **데이터 프레임 확인**:\n",
    "   - SQLite 데이터베이스에서 `pandas`를 사용하여 데이터를 읽어오고, 번역된 결과를 확인. 이를 통해 번역 전후 텍스트 길이 비교 및 데이터 통계를 출력.\n",
    "\n",
    "8. **번역 결과 저장**:\n",
    "   - 번역된 텍스트를 하나의 파일(`translation_results.txt`)로 저장.\n",
    "   \n",
    "### Prompt\n",
    "* 텍스트 파일을 열어 개행 기준으로 데이터를 나누고 sqlite 파일로 저장할것\n",
    "* 이 때 컬럼을  text, length, gpt4omini_trans, gpt4omini_trans 로 만들고 news_text 에는 나눈 텍스트 데이터, length 에는 해당 텍스트 길이가 들어가도록 하고 나머지 컬럼은 비워둘 것\n",
    "* 주석은 한국어로 작성하고 데이터프레임을 불러와서 df 변수에 담고 확인하는 코드를 함께 작성할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e484b67-0185-4e45-ae96-72d3c2bd04cb",
   "metadata": {},
   "source": [
    "* 모델 목록 : https://platform.openai.com/docs/models\n",
    "* 플레이그라운드에서 미리 사용해 보기 : https://platform.openai.com/playground/chat?models=gpt-4o\n",
    "* API 키 발급 : https://platform.openai.com/api-keys\n",
    "* 과금 확인 : https://platform.openai.com/usage\n",
    "* 공식API : [openai-cookbook/examples/book\\_translation/translate\\_latex\\_book.ipynb at main · openai/openai-cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/book_translation/translate_latex_book.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66db8b86-edd9-4f9a-b17c-c698b3f57e3a",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=yp6WuHFhYCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b2025-f510-4803-b0da-85ee077b9581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -Uq openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67499a4-6077-4fb2-ab9f-8160881e8823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "from openai import OpenAI\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def get_first_txt_file(directory='.'):\n",
    "    txt_files = [f for f in os.listdir(directory) if f.endswith('yp6WuHFhYCo_subtitle.txt')]\n",
    "    txt_files.sort()  # 파일명 알파벳 순으로 정렬\n",
    "    return txt_files[0] if txt_files else None\n",
    "\n",
    "def create_chunks(text, chunk_size=1000):\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "def create_db_and_table():\n",
    "    conn = sqlite3.connect('text_chunks.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS chunks\n",
    "                      (id INTEGER PRIMARY KEY,\n",
    "                       original_text TEXT,\n",
    "                       length INTEGER,\n",
    "                       translation TEXT,\n",
    "                       translation_length INTEGER)''')\n",
    "    conn.commit()\n",
    "    return conn, cursor\n",
    "\n",
    "def insert_chunks(cursor, chunks):\n",
    "    for chunk in chunks:\n",
    "        cursor.execute('''INSERT INTO chunks (original_text, length, translation)\n",
    "                          VALUES (?, ?, ?)''', (chunk, len(chunk), None))\n",
    "\n",
    "def translate_text(text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a translator. Translate the given text from English to Korean.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate the following text to Korean: {text}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def update_translations(conn, cursor):\n",
    "    cursor.execute(\"SELECT id, original_text FROM chunks WHERE translation IS NULL\")\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    for row in rows:\n",
    "        id, original_text = row\n",
    "        translated = translate_text(original_text)\n",
    "        translation_length = len(translated)\n",
    "        \n",
    "        cursor.execute('''UPDATE chunks \n",
    "                          SET translation = ?, translation_length = ? \n",
    "                          WHERE id = ?''', (translated, translation_length, id))\n",
    "        conn.commit()  # 각 번역 후 커밋\n",
    "        print(f\"Translated chunk {id}\")\n",
    "\n",
    "def main():\n",
    "    # 첫 번째 .txt 파일 찾기\n",
    "    first_txt_file = get_first_txt_file()\n",
    "    if not first_txt_file:\n",
    "        print(\"No .txt files found in the current directory.\")\n",
    "        return\n",
    "\n",
    "    # 텍스트 파일 읽기\n",
    "    with open(first_txt_file, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # 줄바꿈 문자로 분리\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    # 1000자 단위로 청크 생성\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for line in lines:\n",
    "        if len(current_chunk) + len(line) + 1 > 1000:\n",
    "            chunks.extend(create_chunks(current_chunk))\n",
    "            current_chunk = line + '\\n'\n",
    "        else:\n",
    "            current_chunk += line + '\\n'\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.extend(create_chunks(current_chunk))\n",
    "    \n",
    "    # DB 생성 및 연결\n",
    "    conn, cursor = create_db_and_table()\n",
    "    \n",
    "    # 청크 삽입\n",
    "    insert_chunks(cursor, chunks)\n",
    "    \n",
    "    print(f\"파일 '{first_txt_file}'에서 총 {len(chunks)}개의 청크가 DB에 저장되었습니다.\")\n",
    "\n",
    "    # 번역 수행\n",
    "    print(\"번역을 시작합니다...\")\n",
    "    update_translations(conn, cursor)\n",
    "    print(\"번역이 완료되었습니다.\")\n",
    "\n",
    "    # 결과 출력 (예시로 처음 5개 행)\n",
    "    cursor.execute(\"SELECT * FROM chunks LIMIT 5\")\n",
    "    for row in cursor.fetchall():\n",
    "        print(row)\n",
    "\n",
    "    # 연결 종료\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5443ac22-0660-4310-9552-1df8949a9621",
   "metadata": {},
   "source": [
    "## 번역결과 판다스 데이터프레임으로 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897964d4-cf25-471f-92df-76ef6161ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 데이터를 pandas DataFrame으로 읽어오기\n",
    "import pandas as pd\n",
    "\n",
    "# SQLite 데이터베이스에 다시 연결\n",
    "conn = sqlite3.connect('text_chunks.db')\n",
    "\n",
    "# SQL 쿼리를 사용하여 'chunks' 테이블의 모든 데이터를 DataFrame으로 읽어오기\n",
    "df = pd.read_sql_query(\"SELECT * FROM chunks\", conn)\n",
    "\n",
    "# 연결 종료\n",
    "conn.close()\n",
    "\n",
    "# DataFrame의 처음 몇 행 출력하여 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af2ef6-9d7b-47f6-bf8b-6067ca9404f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame의 정보 출력\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1c5cff-1d60-4450-8d11-60c0ff29f351",
   "metadata": {},
   "source": [
    "## 번역 전 후 길이 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51672f8c-4cd1-4e81-8d54-c357a57cf441",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"length\"] - df[\"translation_length\"]).to_frame().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e547493-8fba-4abb-bab4-6cb4cc571e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a727571-456b-4bec-81d9-796cc5f107c5",
   "metadata": {},
   "source": [
    "## 하나의 파일로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee7bc4-5f96-442c-8792-913c0ae6566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = \"\\n\\n\".join(df[\"translation\"].tolist())\n",
    "translation[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e776f74-43c8-4c04-b078-8afa1b78037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"translation_results.txt\"\n",
    "\n",
    "# 텍스트 파일로 저장\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d13a2-be59-4686-b3c4-120b973a3503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
